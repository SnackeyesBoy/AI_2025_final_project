import os
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    classification_report,
    accuracy_score,
)
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
from transformers import Dinov2Model
from peft import LoraConfig, get_peft_model

# === è¨­å®š (è«‹ç¢ºèªé€™è£¡çš„æª”åæ˜¯å°çš„) ===
CSV_PATH = "isic-2024-challenge/train-metadata.csv"  # ç¢ºä¿è·¯å¾‘æ­£ç¢º
IMAGE_FOLDER = "isic-2024-challenge/train-image/image"  # ç¢ºä¿è·¯å¾‘æ­£ç¢º
MODEL_PATH = "dino_2080_epoch_10.pth"  # <--- è«‹æ”¹æˆä½ è¨“ç·´å‡ºä¾†çš„æœ€å¾Œä¸€å€‹ .pth æª”å
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# === pAUC è¨­å®š ===
# ISIC 2024 Kaggle ä¸»è¦æŒ‡æ¨™ï¼špAUC above 80% TPRï¼ˆè‹¥ä½ è¦ç”¨ 88% TPRï¼Œæ”¹æˆ 0.88 å³å¯ï¼‰
MIN_TPR = 0.80
OUTPUT_SCORES_CSV = "val_inference_scores.csv"  # æ¯ç­†æ¨è«–åˆ†æ•¸è¼¸å‡ºæª”å


def compute_pauc_above_tpr(y_true, y_score, min_tpr: float = 0.80) -> float:
    """
    è¨ˆç®— ISIC 2024 æ‰€ç”¨çš„ pAUC-above-TPRï¼š
      pAUC = âˆ« max(TPR(FPR) - min_tpr, 0) dFPR
    æœ€å¤§å€¼ç‚º 1 - min_tprï¼ˆä¾‹å¦‚ min_tpr=0.8ï¼Œæœ€å¤§ 0.2ï¼‰

    ä½œæ³•ï¼šç”¨ ROC æ›²ç·šæ‰¾å‡º TPR é¦–æ¬¡åˆ°é” min_tpr çš„äº¤é»ï¼ˆç·šæ€§å…§æ’ï¼‰ï¼Œå†ç”¨æ¢¯å½¢æ³•ç©åˆ†ã€‚
    """
    y_true = np.asarray(y_true).astype(int)
    y_score = np.asarray(y_score).astype(float)

    # è‹¥åªå‰©å–®ä¸€é¡åˆ¥ï¼Œroc_curve æœƒå¤±æ•—ï¼›æ­¤æ™‚ pAUC å®šç¾©ä¸Šå¯è¦–ç‚º 0
    if len(np.unique(y_true)) < 2:
        return 0.0

    fpr, tpr, _ = roc_curve(y_true, y_score)

    # tpr å–®èª¿ä¸æ¸›ï¼›æ‰¾ç¬¬ä¸€å€‹ >= min_tpr çš„ç´¢å¼•
    idx = np.searchsorted(tpr, min_tpr, side="left")
    if idx >= len(tpr):
        return 0.0  # æ°¸é é”ä¸åˆ° min_tpr

    # å°‡ã€Œå‰›å¥½è·¨é min_tprã€çš„äº¤é»è£œé€²ä¾†ï¼Œé¿å…ç©åˆ†èª¤å·®
    if tpr[idx] == min_tpr:
        fpr_start = fpr[idx]
        fpr_seg = fpr[idx:]
        tpr_seg = tpr[idx:]
    else:
        if idx == 0:
            fpr_start = fpr[0]
        else:
            tpr1, tpr2 = tpr[idx - 1], tpr[idx]
            fpr1, fpr2 = fpr[idx - 1], fpr[idx]
            # ç·šæ€§å…§æ’ï¼štpr = tpr1 + w*(tpr2-tpr1) = min_tpr
            w = (min_tpr - tpr1) / (tpr2 - tpr1 + 1e-12)
            fpr_start = fpr1 + w * (fpr2 - fpr1)

        fpr_seg = np.concatenate([[fpr_start], fpr[idx:]])
        tpr_seg = np.concatenate([[min_tpr], tpr[idx:]])

    # å° (tpr - min_tpr) é€²è¡Œç©åˆ†
    pauc = np.trapz(tpr_seg - min_tpr, fpr_seg)
    return float(max(pauc, 0.0))


# === 1. å¿…é ˆé‡æ–°å®šç¾©æ¨¡å‹æ¶æ§‹ (è·Ÿè¨“ç·´æ™‚ä¸€æ¨¡ä¸€æ¨£) ===
class SkinClassifier(nn.Module):
    def __init__(self, encoder):
        super().__init__()
        self.encoder = encoder
        self.classifier = nn.Linear(768, 2)  # DINO æ˜¯äºŒåˆ†é¡

    def forward(self, x):
        outputs = self.encoder(x)
        return self.classifier(outputs.last_hidden_state[:, 0, :])


# === 2. è³‡æ–™é›†é¡åˆ¥ ===
class ISICDataset(Dataset):
    def __init__(self, df, img_dir, transform=None):
        self.df = df.reset_index(drop=True)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        isic_id = row["isic_id"]
        img_name = f"{isic_id}.jpg"
        path = os.path.join(self.img_dir, img_name)

        try:
            img = Image.open(path).convert("RGB")
        except Exception:
            img = Image.new("RGB", (224, 224))  # è®€å¤±æ•—çµ¦é»‘åœ–

        if self.transform:
            img = self.transform(img)

        return img, int(row["target"]), isic_id  # å›å‚³ isic_id æ–¹ä¾¿å„²å­˜æ¯ç­†åˆ†æ•¸


def main():
    print(f"ğŸš€ æ­£åœ¨è®€å–è³‡æ–™... (ä½¿ç”¨æ¨¡å‹: {MODEL_PATH})")

    # è®€å– CSV (åŠ ä¸Š low_memory é˜²æ­¢è­¦å‘Š)
    if not os.path.exists(CSV_PATH):
        print(f"âŒ æ‰¾ä¸åˆ° CSV: {CSV_PATH}")
        return
    df = pd.read_csv(CSV_PATH, low_memory=False)

    # åˆ‡åˆ†é©—è­‰é›† (å›ºå®š random_state=42 ç¢ºä¿è·Ÿè¨“ç·´æ™‚åˆ‡çš„ä¸€æ¨£)
    _, val_df = train_test_split(
        df, test_size=0.1, stratify=df["target"], random_state=42
    )

    # === æ¡æ¨£ç­–ç•¥ (è·Ÿ EfficientNet é‚£é‚Šä¸€æ¨£ï¼Œå–éƒ¨åˆ†è‰¯æ€§+å…¨éƒ¨æƒ¡æ€§) ===
    val_pos = val_df[val_df["target"] == 1]
    # å– 5000 ç­†è‰¯æ€§ä¾†æ¸¬è©¦ (å¤ªå¤šè·‘å¾ˆæ…¢ï¼Œå¤ªå°‘ä¸æº–)
    val_neg = val_df[val_df["target"] == 0].sample(n=5000, random_state=42)
    val_eval_df = (
        pd.concat([val_pos, val_neg]).sample(frac=1, random_state=42).reset_index(drop=True)
    )

    print(
        f"ğŸ“Š è©•ä¼°æ¨£æœ¬æ•¸: {len(val_eval_df)} (æƒ¡æ€§: {len(val_pos)}, è‰¯æ€§: {len(val_neg)})"
    )

    # === 3. è¼‰å…¥ DINOv2 æ¨¡å‹çµæ§‹ ===
    print("ğŸ¦– é‡å»º DINOv2 + LoRA æ¨¡å‹æ¶æ§‹...")
    base_model = Dinov2Model.from_pretrained("facebook/dinov2-with-registers-base")

    # LoRA è¨­å®š (å¿…é ˆè·Ÿè¨“ç·´æ™‚å®Œå…¨ä¸€æ¨£)
    peft_config = LoraConfig(
        r=16, lora_alpha=16, target_modules=["query", "value"], lora_dropout=0.1, bias="none"
    )
    base_model = get_peft_model(base_model, peft_config)

    # å¥—ä¸Šåˆ†é¡é ­
    model = SkinClassifier(base_model)

    # === 4. è¼‰å…¥æ¬Šé‡ ===
    print(f"ğŸ“¥ è¼‰å…¥æ¬Šé‡æª”æ¡ˆ: {MODEL_PATH} ...")
    if not os.path.exists(MODEL_PATH):
        print("âŒ æ‰¾ä¸åˆ°æ¬Šé‡æª”ï¼è«‹ç¢ºèªæª”åæ˜¯å¦æ­£ç¢ºã€‚")
        return

    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
        print("âœ… æ¬Šé‡è¼‰å…¥æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¬Šé‡è¼‰å…¥å¤±æ•—ï¼Œå¯èƒ½æ˜¯æ¶æ§‹ä¸å°ç¨±ã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
        return

    model.to(DEVICE)
    model.eval()

    # === 5. é–‹å§‹é æ¸¬ ===
    tfm = transforms.Compose(
        [
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ]
    )

    loader = DataLoader(
        ISICDataset(val_eval_df, IMAGE_FOLDER, tfm),
        batch_size=32,
        shuffle=False,
        num_workers=4,
    )

    probs = []  # å­˜æƒ¡æ€§çš„æ©Ÿç‡
    targs = []  # å­˜çœŸå¯¦æ¨™ç±¤
    ids = []  # å­˜ isic_idï¼ˆæ¯ç­†ï¼‰

    print("ğŸ” é–‹å§‹æ¨è«–...")
    with torch.no_grad():
        for x, y, batch_ids in tqdm(loader, desc="Evaluating"):
            x = x.to(DEVICE)
            out = model(x)  # è¼¸å‡ºæ˜¯ [Batch, 2]

            # DINO è¼¸å‡ºå…©æ¬„ï¼Œæˆ‘å€‘è¦ç”¨ Softmax è½‰æˆæ©Ÿç‡ï¼Œä¸¦å–ç¬¬ 1 æ¬„ (æƒ¡æ€§æ©Ÿç‡)
            prob_malignant = torch.softmax(out, dim=1)[:, 1]

            probs.extend(prob_malignant.detach().cpu().numpy().tolist())
            targs.extend(y.numpy().tolist())
            ids.extend(list(batch_ids))

    # === 6. å„²å­˜æ¯ç­†åˆ†æ•¸ ===
    scores_df = pd.DataFrame(
        {"isic_id": ids, "target": targs, "prob_malignant": probs}
    )
    scores_df.to_csv(OUTPUT_SCORES_CSV, index=False)
    print(f"ğŸ’¾ å·²è¼¸å‡ºæ¯ç­†æ¨è«–åˆ†æ•¸: {OUTPUT_SCORES_CSV}")

    # === 7. ç”¢ç”Ÿå ±è¡¨ ===
    threshold = 0.5
    preds_bin = [1 if p > threshold else 0 for p in probs]

    print("\n" + "=" * 40)
    print(f"ã€ DINOv2 æœ€çµ‚è©•ä¼°å ±å‘Š (Threshold={threshold}) ã€‘")

    # Full AUC
    try:
        auc = roc_auc_score(targs, probs)
        print(f"AUC Score: {auc:.4f}")
    except Exception:
        print("AUC Score: ç„¡æ³•è¨ˆç®— (å¯èƒ½æ˜¯åªæœ‰å–®ä¸€é¡åˆ¥)")

    # pAUC (ISIC 2024)
    pauc = compute_pauc_above_tpr(targs, probs, min_tpr=MIN_TPR)
    print(f"pAUC-above-TPR (min_tpr={MIN_TPR:.2f}): {pauc:.6f}  (max={1-MIN_TPR:.2f})")
    print(f"pAUC normalized (pAUC/(1-min_tpr)): {pauc / max(1e-12, (1 - MIN_TPR)):.6f}")

    print(f"Accuracy:  {accuracy_score(targs, preds_bin):.4f}")
    print("-" * 40)
    print(classification_report(targs, preds_bin, target_names=["Benign", "Malignant"]))

    # é¡¯ç¤ºæ··æ·†çŸ©é™£
    cm = confusion_matrix(targs, preds_bin)
    print("æ··æ·†çŸ©é™£ (Confusion Matrix):")
    print(cm)
    print(f"\n[è‰¯æ€§é æ¸¬å°: {cm[0][0]}]  [èª¤åˆ¤ç‚ºæƒ¡æ€§: {cm[0][1]}]")
    print(f"[èª¤åˆ¤ç‚ºè‰¯æ€§: {cm[1][0]}]  [æƒ¡æ€§é æ¸¬å°: {cm[1][1]}] <--- é‡é»çœ‹é€™è£¡ï¼")
    print("=" * 40)


if __name__ == "__main__":
    main()
