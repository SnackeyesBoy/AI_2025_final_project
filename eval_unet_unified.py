import os
import torch
import pandas as pd
import numpy as np

from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    roc_auc_score, confusion_matrix, classification_report,
    accuracy_score, f1_score
)
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import roc_curve, auc

from isic_pauc import isic_pauc_above_tpr

# ISIC2024: pAUC above 80% TPR6
MIN_TPR = 0.80

# ==========================================
# 1. è¨­å®šå€åŸŸï¼ˆä½ è‡ªè¡Œæ”¹è·¯å¾‘ï¼‰
# ==========================================
CSV_PATH   = "D:/Jeff/save/b2025/course/AI/isic-2024-challenge/train-metadata.csv"
IMAGE_FOLDER  = "D:/Jeff/save/b2025/course/AI/isic-2024-challenge/train-image/image"
MODEL_PATH = "best_unet_encoder_cls.pth"  # ä½ çš„ U-Net encoder classifier æ¬Šé‡
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

IMG_SIZE = 224
UNET_BASE = 64
BATCH_SIZE = 64
NUM_WORKERS = 0
RANDOM_STATE = 42

# ==========================================
# 2. è³‡æ–™é›†é¡åˆ¥ï¼ˆæ²¿ç”¨ eval (1).py çš„è®€å–é¢¨æ ¼ï¼‰
# ==========================================
class ISICDataset(Dataset):
    def __init__(self, df, img_dir, transform=None):
        self.df = df.reset_index(drop=True)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        path = os.path.join(self.img_dir, f"{row['isic_id']}.jpg")
        try:
            img = Image.open(path).convert("RGB")
        except:
            img = Image.new("RGB", (IMG_SIZE, IMG_SIZE))  # è®€ä¸åˆ°çµ¦é»‘åœ–ï¼ˆèˆ‡åƒè€ƒç¨‹å¼ä¸€è‡´ï¼‰
        if self.transform:
            img = self.transform(img)
        return img, torch.tensor(row["target"], dtype=torch.float32), row["isic_id"]


# ==========================================
# 3. U-Net encoder classifierï¼ˆä¸è¼¸å‡º maskï¼‰
# ==========================================
class ConvBlock(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.SiLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.SiLU(inplace=True),
        )

    def forward(self, x):
        return self.net(x)

class UNetEncoderClassifier(nn.Module):
    def __init__(self, in_ch=3, base=64, dropout=0.2):
        super().__init__()
        self.pool = nn.MaxPool2d(2)

        self.enc1 = ConvBlock(in_ch, base)
        self.enc2 = ConvBlock(base, base * 2)
        self.enc3 = ConvBlock(base * 2, base * 4)
        self.enc4 = ConvBlock(base * 4, base * 8)
        self.bottleneck = ConvBlock(base * 8, base * 16)

        self.drop = nn.Dropout(dropout)
        self.fc = nn.Linear(base * 16, 1)

    def forward(self, x):
        x = self.enc1(x); x = self.pool(x)
        x = self.enc2(x); x = self.pool(x)
        x = self.enc3(x); x = self.pool(x)
        x = self.enc4(x); x = self.pool(x)
        x = self.bottleneck(x)

        x = F.adaptive_avg_pool2d(x, 1).flatten(1)
        x = self.drop(x)
        logit = self.fc(x).squeeze(1)   # (B,)
        return logit

# ==========================================
# 4. æ¬Šé‡è¼‰å…¥ï¼ˆæ”¯æ´å…©ç¨®æ ¼å¼ï¼‰
#    - state_dict ç›´æ¥å­˜
#    - æˆ– {"model": state_dict, "cfg": ...}
# ==========================================
def load_checkpoint(model, model_path, device):
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ¬Šé‡ï¼š{model_path}")

    ckpt = torch.load(model_path, map_location=device)

    if isinstance(ckpt, dict) and "model" in ckpt:
        state_dict = ckpt["model"]
    else:
        state_dict = ckpt

    model.load_state_dict(state_dict, strict=True)
    return model

# ==========================================
# 5. ä¸»ç¨‹å¼ï¼ˆæµç¨‹å°é½Š eval (1).pyï¼‰
# ==========================================
def main():
    print("æ­£åœ¨è®€å–ä¸¦æº–å‚™è©•ä¼°è³‡æ–™...")
    try:
        df = pd.read_csv(CSV_PATH, low_memory=False)
    except:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° train-metadata.csv")
        return

    # åˆ‡åˆ†å‡ºé©—è­‰é›†ï¼ˆèˆ‡åƒè€ƒç¨‹å¼ä¸€è‡´ï¼‰
    _, val_df = train_test_split(
        df, test_size=0.1, stratify=df["target"], random_state=RANDOM_STATE
    )

    # è©•ä¼°æŠ½æ¨£ï¼šå…¨éƒ¨æƒ¡æ€§ + éš¨æ©Ÿ 5000 è‰¯æ€§ï¼ˆèˆ‡åƒè€ƒç¨‹å¼ä¸€è‡´ï¼‰
    val_pos = val_df[val_df["target"] == 1]
    val_neg_n = min(5000, len(val_df[val_df["target"] == 0]))
    val_neg = val_df[val_df["target"] == 0].sample(n=val_neg_n, random_state=RANDOM_STATE)

    val_eval_df = (
        pd.concat([val_pos, val_neg])
        .sample(frac=1, random_state=RANDOM_STATE)
        .reset_index(drop=True)
    )

    print(f"è©•ä¼°æ¨£æœ¬ç¸½æ•¸: {len(val_eval_df)}")
    print(f" -> åŒ…å«æƒ¡æ€§æ¨£æœ¬: {len(val_pos)} (å…¨éƒ¨ç´å…¥)")
    print(f" -> åŒ…å«è‰¯æ€§æ¨£æœ¬: {len(val_neg)} (éš¨æ©ŸæŠ½æ¨£)")

    print("è¼‰å…¥æ¨¡å‹èˆ‡æ¬Šé‡...")
    model = UNetEncoderClassifier(in_ch=3, base=UNET_BASE, dropout=0.2)
    model = load_checkpoint(model, MODEL_PATH, DEVICE)
    model.to(DEVICE)
    model.eval()
    print("âœ… æˆåŠŸè¼‰å…¥æ¨¡å‹æ¬Šé‡")

    tfm = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    ])

    loader = DataLoader(
        ISICDataset(val_eval_df, IMAGE_FOLDER, tfm),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=NUM_WORKERS,
    )

    preds, targs, ids = [], [], []

    with torch.no_grad():
        for x, y, isic_id in tqdm(loader, desc="æ­£åœ¨è©•ä¼° U-Net åˆ†é¡æ¨¡å‹"):
            x = x.to(DEVICE, non_blocking=True)
            logits = model(x)
            prob = torch.sigmoid(logits).cpu().numpy()

            preds.extend(prob.tolist())
            targs.extend(y.numpy().tolist())
            ids.extend(isic_id)


    
    preds = np.array(preds, dtype=np.float64)
    targs = np.array(targs, dtype=np.int64)

    # ===============================
    # å„²å­˜æ‰€æœ‰æ¨è«–åˆ†æ•¸
    # ===============================
    out_df = pd.DataFrame({
        "isic_id": ids,
        "target": targs,
        "pred_score": preds
    })

    out_path = "unet_val_predictions.csv"
    out_df.to_csv(out_path, index=False)
    print(f"âœ… å·²å„²å­˜æ‰€æœ‰æ¨è«–åˆ†æ•¸è‡³: {out_path}")

    # === è‡ªå‹•å°‹æ‰¾æœ€ä½³é–€æª» (Threshold Tuning) ===
    print("\næ­£åœ¨å°‹æ‰¾æœ€ä½³åˆ†é¡é–€æª» (ä»¥ F1-Score ç‚ºåŸºæº–)...")
    best_f1 = -1.0
    best_thresh = 0.5

    for thresh in np.arange(0.01, 0.60, 0.01):
        preds_bin = (preds > thresh).astype(int)
        f1 = f1_score(targs, preds_bin)
        if f1 > best_f1:
            best_f1 = f1
            best_thresh = float(thresh)

    print(f"ğŸ† æœ€ä½³é–€æª»å€¼å·²é–å®š: {best_thresh:.2f} | Best F1={best_f1:.4f}")

    final_preds_bin = (preds > best_thresh).astype(int)

    # æ··æ·†çŸ©é™£
    cm = confusion_matrix(targs, final_preds_bin)
    if cm.shape == (2, 2):
        tn, fp, fn, tp = cm.ravel()
    else:
        tn = fp = fn = tp = 0

    # å ±è¡¨ï¼ˆèˆ‡åƒè€ƒç¨‹å¼ä¸€è‡´çš„è¼¸å‡ºé¢¨æ ¼ï¼‰
    print("\n" + "=" * 50)
    print("ã€ æœ€çµ‚å ±å‘Š ã€‘")
    print("=" * 50)
    print(f"æœ€ä½³é–€æª»å€¼ (Threshold): {best_thresh:.2f}")

    # AUCï¼šéœ€è¦åŒæ™‚å­˜åœ¨ 0/1 æ‰èƒ½ç®—
    if len(np.unique(targs)) == 2:
        print(f"AUC (é‘‘åˆ¥åŠ›):          {roc_auc_score(targs, preds):.4f}")
    else:
        print("AUC (é‘‘åˆ¥åŠ›):          N/Aï¼ˆé©—è­‰è³‡æ–™åªæœ‰å–®ä¸€é¡åˆ¥ï¼‰")

    print(f"Accuracy (æº–ç¢ºç‡):     {accuracy_score(targs, final_preds_bin):.4f}")
    print("-" * 50)

    print("æ··æ·†çŸ©é™£ (Confusion Matrix):")
    print(f"[[{tn}\t{fp}]")
    print(f" [{fn}\t{tp}]]\n")
    print(f"[è‰¯æ€§é æ¸¬å°: {tn}]  [èª¤åˆ¤ç‚ºæƒ¡æ€§: {fp}]")
    print(f"[èª¤åˆ¤ç‚ºè‰¯æ€§: {fn}]  [æƒ¡æ€§é æ¸¬å°: {tp}] <--- é‡é»çœ‹é€™è£¡ï¼(Recallé«˜)")

    print("-" * 50)
    print("è©³ç´°åˆ†é¡æŒ‡æ¨™:")
    print(classification_report(targs, final_preds_bin, target_names=["Benign", "Malignant"]))
    print("=" * 50)
    # ===============================
    # pAUCï¼ˆISIC 2024 æ ¸å¿ƒæŒ‡æ¨™ï¼‰
    # ===============================
    if len(np.unique(targs)) == 2:
        raw_pauc = isic_pauc_above_tpr(targs, preds, min_tpr=MIN_TPR, normalize=False)
        norm_pauc = isic_pauc_above_tpr(targs, preds, min_tpr=MIN_TPR, normalize=True)

        print(f"pAUC (TPR >= {MIN_TPR:.2f}, raw):        {raw_pauc:.6f}")
        print(f"pAUC (TPR >= {MIN_TPR:.2f}, normalized): {norm_pauc:.6f}")
    else:
        print("pAUC: N/Aï¼ˆé©—è­‰è³‡æ–™åªæœ‰å–®ä¸€é¡åˆ¥ï¼‰")

if __name__ == "__main__":
    main()
